{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41e74c11",
   "metadata": {},
   "source": [
    "# Lab 5 Databricks Jobs\n",
    "\n",
    "## Exercise 1\n",
    "\n",
    "1. Navigate to the Jobs and Pipelines screen in Databricks. This is the central place for orchestration in Databricks.\n",
    "\n",
    "2. Notice at the top that there are 3 buttons for each kind of type: Job, ETL Pipeline and Ingestion  pipeline.\n",
    "\n",
    "3. We will start with a very basic Job: Run a notebook once a week. We can do that directly from the notebook.\n",
    "\n",
    "4. Create a new notebook called Vehicle data load into delta table\n",
    "\n",
    "5. Grab your code from yesterday where you read vehicle data from parquet format and insert it into a table in your catalog. Make sure to overwrite the table if it already exists.\n",
    "\n",
    "6. Click on the button at the top right called schedule. Choose advanced schedule and configure the job to run every monday at 10.15 Copenhagen time.\n",
    "\n",
    "7. Go back to the Jobs and Pipelines screen and find you new job.\n",
    "\n",
    "8. Click on the job and run it now.\n",
    "\n",
    "9. Notice you have two tabs Runs and Tasks. Runs will show history of runs and status if it's running \n",
    "\n",
    "10. Tasks will show you a diagram of each task in the Job. This simple job only had one task.\n",
    "\n",
    "## Exercise 2\n",
    "\n",
    "1. Go back to your notebook and add 3 text parameters at the top: catalog_name, schema_name and table_name (use the widget syntax)\n",
    "\n",
    "2. Create the schema if it does not exists using the schema name from the parameter\n",
    "\n",
    "2. Then use the parameters in the code when you write data to the table. \n",
    "\n",
    "3. Now go into the Jobs and Pipelines and locate your notebook task. Add a parameter with key tablename and value vehicledata for the task. Specify your catalog and schema as key.\n",
    "\n",
    "4. Try to run the job and check whether it succesfully writes the data in the table you have specified in the parameters.\n",
    "\n",
    "## Exercise 3\n",
    "\n",
    "1. Create a new notebook called \"Task 1 Set filename\". Make a Python cell where you set a task variable called filename birds.csv\n",
    "\n",
    "2. Create another notebook called \"Task 2 Get filename from previous task\". Use the syntax to exchange data from a previous task.\n",
    "\n",
    "3. In the Jobs and Pipelines screen create a new job called \"Conditional logic and getting data from a previous task\"\n",
    "\n",
    "4. Create two tasks in your pipeline where you execute the two notebooks in a sequentiel order af each other.\n",
    "\n",
    "5. Add an \"If\" task to your job as a 3rd task in the flow. Use the {{}} to check whether the current day is a weekday. Compare the result with true with lowercase letters. \n",
    "\n",
    "6. Create a Python notebook called Task 3 Is weekday and just add a simple line with a print statement\n",
    "\n",
    "7. Clone the notebok and rename it to Task 4 Is Not weekday.\n",
    "\n",
    "8. Assign the two notebooks to tasks in your pipeline for the conditional logic with the if. \n",
    "\n",
    "9. Test your code\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ". \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3633d1c7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
